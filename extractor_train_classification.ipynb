{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-28 14:54:52.773978: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2025-01-28 14:54:52.792796: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2025-01-28 14:54:52.799134: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-01-28 14:54:52.813137: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-01-28 14:54:53.782822: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import random\n",
    "import numpy as np\n",
    "import glob\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from PIL import Image as PILImage\n",
    "from PIL.ExifTags import TAGS\n",
    "\n",
    "from IPython.display import display\n",
    "\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.applications import ResNet50\n",
    "from keras_resnet.models import ResNet18 \n",
    "from tensorflow.keras.utils import Sequence\n",
    "from tensorflow.keras.layers import Input\n",
    "from tensorflow.keras import regularizers\n",
    "\n",
    "from keras.layers import Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 32\n",
    "IMAGE_SIZE = (256, 256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def imshow(a, size=1.0):\n",
    "    # Clip and convert the image to uint8\n",
    "    a = a.clip(0, 255).astype(\"uint8\")\n",
    "    \n",
    "    # Resize the image if a size factor is provided\n",
    "    if size != 1.0:\n",
    "        new_dim = (int(a.shape[1] * size), int(a.shape[0] * size))\n",
    "        a = cv2.resize(a, new_dim, interpolation=cv2.INTER_AREA)\n",
    "    \n",
    "    \n",
    "    # Display the image\n",
    "    display(PILImage.fromarray(a))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_label(file_path):\n",
    "    label = file_path.split(\"/\")[-2]\n",
    "    label = label.split(\".\")[-2]\n",
    "    label = int(label)\n",
    "    return label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_image(file_path):\n",
    "    img = cv2.imread(file_path)\n",
    "    img = cv2.resize(img, IMAGE_SIZE)\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataGenerator(Sequence):\n",
    "    def __init__(self, img_files, labels, batch_size, image_size, augment = False, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.img_files = img_files\n",
    "        self.labels = labels\n",
    "        self.batch_size = batch_size\n",
    "        self.image_size = image_size\n",
    "        self.augment = augment\n",
    "      \n",
    "    def __len__(self):\n",
    "        return len(self.img_files) // self.batch_size\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        start = index * self.batch_size\n",
    "        end = start + self.batch_size\n",
    "        batch_images = self.img_files[start:end]\n",
    "        batch_labels = self.labels[start:end]\n",
    "        \n",
    "        imgs, labels = [], []\n",
    "        \n",
    "        for i in range(len(batch_images)):\n",
    "            img = read_image(batch_images[i])\n",
    "            \n",
    "            label = batch_labels[i]\n",
    "            \n",
    "            if self.augment:\n",
    "                img_aug = self.default_augmentations(img)\n",
    "                img_aug = img_aug / 255.0\n",
    "                \n",
    "                imgs.append(img_aug)\n",
    "                labels.append(label)\n",
    "            \n",
    "            img = img / 255.0\n",
    "            \n",
    "            imgs.append(img)\n",
    "            labels.append(label)\n",
    "        \n",
    "        imgs = np.array(imgs)\n",
    "        labels = np.array(labels)\n",
    "     \n",
    "        return imgs, tf.keras.utils.to_categorical(labels, num_classes=107)\n",
    "\n",
    "    def default_augmentations(self, img):\n",
    "        # Define small augmentations manually and apply them directly to the image\n",
    "        img = tf.image.random_flip_left_right(img)\n",
    "        img = tf.image.random_flip_up_down(img)\n",
    "        img = tf.image.random_brightness(img, max_delta=0.1)  # Adjust brightness\n",
    "        img = tf.image.random_contrast(img, lower=0.9, upper=1.1)  # Adjust contrast\n",
    "        img = tf.image.random_saturation(img, lower=0.9, upper=1.1)  # Adjust saturation\n",
    "        img = tf.image.rot90(img, k=np.random.randint(0, 4))  # Random 90Â° rotations\n",
    "        \n",
    "        img = tf.cast(img, tf.float32)\n",
    "        img = img / 255.0\n",
    "    \n",
    "        return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of images found:  11496\n",
      "Number of labels found:  11496\n",
      "Number of unique labels:  106\n"
     ]
    }
   ],
   "source": [
    "data_folder = \"Data_Final/*\"\n",
    "\n",
    "image_files = glob.glob(os.path.join(data_folder, \"*.jpg\"), recursive=True)\n",
    "\n",
    "labels = [get_label(file_path) for file_path in image_files]\n",
    "\n",
    "print(\"Number of images found: \", len(image_files))\n",
    "print(\"Number of labels found: \", len(labels))\n",
    "print(\"Number of unique labels: \", len(set(labels)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x, val_x, train_y, val_y = train_test_split(image_files, labels, test_size=0.2, random_state=42, stratify=labels)\n",
    "\n",
    "val_x, test_x, val_y, test_y = train_test_split(val_x, val_y, test_size=0.5, random_state=42, stratify=val_y)\n",
    "\n",
    "train_gen = DataGenerator(train_x, train_y, BATCH_SIZE, IMAGE_SIZE, augment=True)\n",
    "val_gen = DataGenerator(val_x, val_y, BATCH_SIZE * 2, IMAGE_SIZE)\n",
    "test_gen = DataGenerator(test_x, test_y, BATCH_SIZE * 2, IMAGE_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class L2Normalization(Layer):\n",
    "    def call(self, inputs):\n",
    "        return tf.math.l2_normalize(inputs, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1738072495.081342 1854293 cuda_executor.cc:1001] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "I0000 00:00:1738072495.341855 1854293 cuda_executor.cc:1001] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "I0000 00:00:1738072495.342090 1854293 cuda_executor.cc:1001] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "I0000 00:00:1738072495.346511 1854293 cuda_executor.cc:1001] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "I0000 00:00:1738072495.346626 1854293 cuda_executor.cc:1001] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "I0000 00:00:1738072495.346686 1854293 cuda_executor.cc:1001] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "I0000 00:00:1738072495.701545 1854293 cuda_executor.cc:1001] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "I0000 00:00:1738072495.701795 1854293 cuda_executor.cc:1001] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-01-28 14:54:55.701833: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2112] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.\n",
      "I0000 00:00:1738072495.702055 1854293 cuda_executor.cc:1001] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-01-28 14:54:55.702643: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2021] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 1767 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3050 Laptop GPU, pci bus id: 0000:01:00.0, compute capability: 8.6\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"EmbeddingNetwork\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"EmbeddingNetwork\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">âââââââââââââââââââââââââââââââââââ³âââââââââââââââââââââââââ³ââââââââââââââââ\n",
       "â<span style=\"font-weight: bold\"> Layer (type)                    </span>â<span style=\"font-weight: bold\"> Output Shape           </span>â<span style=\"font-weight: bold\">       Param # </span>â\n",
       "â¡âââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââ©\n",
       "â input_layer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        â (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)    â             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â\n",
       "âââââââââââââââââââââââââââââââââââ¼âââââââââââââââââââââââââ¼ââââââââââââââââ¤\n",
       "â conv2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                 â (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)   â         <span style=\"color: #00af00; text-decoration-color: #00af00\">4,736</span> â\n",
       "âââââââââââââââââââââââââââââââââââ¼âââââââââââââââââââââââââ¼ââââââââââââââââ¤\n",
       "â batch_normalization             â (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)   â           <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> â\n",
       "â (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            â                        â               â\n",
       "âââââââââââââââââââââââââââââââââââ¼âââââââââââââââââââââââââ¼ââââââââââââââââ¤\n",
       "â max_pooling2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)    â (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     â             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â\n",
       "âââââââââââââââââââââââââââââââââââ¼âââââââââââââââââââââââââ¼ââââââââââââââââ¤\n",
       "â conv2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               â (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     â        <span style=\"color: #00af00; text-decoration-color: #00af00\">51,264</span> â\n",
       "âââââââââââââââââââââââââââââââââââ¼âââââââââââââââââââââââââ¼ââââââââââââââââ¤\n",
       "â batch_normalization_1           â (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     â           <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> â\n",
       "â (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            â                        â               â\n",
       "âââââââââââââââââââââââââââââââââââ¼âââââââââââââââââââââââââ¼ââââââââââââââââ¤\n",
       "â max_pooling2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)  â (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     â             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â\n",
       "âââââââââââââââââââââââââââââââââââ¼âââââââââââââââââââââââââ¼ââââââââââââââââ¤\n",
       "â conv2d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               â (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    â        <span style=\"color: #00af00; text-decoration-color: #00af00\">73,856</span> â\n",
       "âââââââââââââââââââââââââââââââââââ¼âââââââââââââââââââââââââ¼ââââââââââââââââ¤\n",
       "â batch_normalization_2           â (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    â           <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> â\n",
       "â (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            â                        â               â\n",
       "âââââââââââââââââââââââââââââââââââ¼âââââââââââââââââââââââââ¼ââââââââââââââââ¤\n",
       "â conv2d_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               â (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    â       <span style=\"color: #00af00; text-decoration-color: #00af00\">147,584</span> â\n",
       "âââââââââââââââââââââââââââââââââââ¼âââââââââââââââââââââââââ¼ââââââââââââââââ¤\n",
       "â batch_normalization_3           â (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    â           <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> â\n",
       "â (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            â                        â               â\n",
       "âââââââââââââââââââââââââââââââââââ¼âââââââââââââââââââââââââ¼ââââââââââââââââ¤\n",
       "â max_pooling2d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)  â (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)      â             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â\n",
       "âââââââââââââââââââââââââââââââââââ¼âââââââââââââââââââââââââ¼ââââââââââââââââ¤\n",
       "â conv2d_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               â (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)      â       <span style=\"color: #00af00; text-decoration-color: #00af00\">295,168</span> â\n",
       "âââââââââââââââââââââââââââââââââââ¼âââââââââââââââââââââââââ¼ââââââââââââââââ¤\n",
       "â batch_normalization_4           â (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)      â         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> â\n",
       "â (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            â                        â               â\n",
       "âââââââââââââââââââââââââââââââââââ¼âââââââââââââââââââââââââ¼ââââââââââââââââ¤\n",
       "â conv2d_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               â (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)      â       <span style=\"color: #00af00; text-decoration-color: #00af00\">590,080</span> â\n",
       "âââââââââââââââââââââââââââââââââââ¼âââââââââââââââââââââââââ¼ââââââââââââââââ¤\n",
       "â batch_normalization_5           â (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)      â         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> â\n",
       "â (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            â                        â               â\n",
       "âââââââââââââââââââââââââââââââââââ¼âââââââââââââââââââââââââ¼ââââââââââââââââ¤\n",
       "â max_pooling2d_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)  â (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)      â             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â\n",
       "âââââââââââââââââââââââââââââââââââ¼âââââââââââââââââââââââââ¼ââââââââââââââââ¤\n",
       "â conv2d_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               â (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)      â        <span style=\"color: #00af00; text-decoration-color: #00af00\">65,792</span> â\n",
       "âââââââââââââââââââââââââââââââââââ¼âââââââââââââââââââââââââ¼ââââââââââââââââ¤\n",
       "â batch_normalization_6           â (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)      â         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> â\n",
       "â (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            â                        â               â\n",
       "âââââââââââââââââââââââââââââââââââ¼âââââââââââââââââââââââââ¼ââââââââââââââââ¤\n",
       "â global_average_pooling2d        â (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            â             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â\n",
       "â (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePooling2D</span>)        â                        â               â\n",
       "âââââââââââââââââââââââââââââââââââ¼âââââââââââââââââââââââââ¼ââââââââââââââââ¤\n",
       "â dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   â (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            â       <span style=\"color: #00af00; text-decoration-color: #00af00\">131,584</span> â\n",
       "âââââââââââââââââââââââââââââââââââ¼âââââââââââââââââââââââââ¼ââââââââââââââââ¤\n",
       "â l2_normalization                â (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            â             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â\n",
       "â (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">L2Normalization</span>)               â                        â               â\n",
       "âââââââââââââââââââââââââââââââââââ¼âââââââââââââââââââââââââ¼ââââââââââââââââ¤\n",
       "â dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)               â (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            â             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â\n",
       "âââââââââââââââââââââââââââââââââââ´âââââââââââââââââââââââââ´ââââââââââââââââ\n",
       "</pre>\n"
      ],
      "text/plain": [
       "âââââââââââââââââââââââââââââââââââ³âââââââââââââââââââââââââ³ââââââââââââââââ\n",
       "â\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0mâ\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0mâ\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0mâ\n",
       "â¡âââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââ©\n",
       "â input_layer (\u001b[38;5;33mInputLayer\u001b[0m)        â (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m3\u001b[0m)    â             \u001b[38;5;34m0\u001b[0m â\n",
       "âââââââââââââââââââââââââââââââââââ¼âââââââââââââââââââââââââ¼ââââââââââââââââ¤\n",
       "â conv2d (\u001b[38;5;33mConv2D\u001b[0m)                 â (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m32\u001b[0m)   â         \u001b[38;5;34m4,736\u001b[0m â\n",
       "âââââââââââââââââââââââââââââââââââ¼âââââââââââââââââââââââââ¼ââââââââââââââââ¤\n",
       "â batch_normalization             â (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m32\u001b[0m)   â           \u001b[38;5;34m128\u001b[0m â\n",
       "â (\u001b[38;5;33mBatchNormalization\u001b[0m)            â                        â               â\n",
       "âââââââââââââââââââââââââââââââââââ¼âââââââââââââââââââââââââ¼ââââââââââââââââ¤\n",
       "â max_pooling2d (\u001b[38;5;33mMaxPooling2D\u001b[0m)    â (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m32\u001b[0m)     â             \u001b[38;5;34m0\u001b[0m â\n",
       "âââââââââââââââââââââââââââââââââââ¼âââââââââââââââââââââââââ¼ââââââââââââââââ¤\n",
       "â conv2d_1 (\u001b[38;5;33mConv2D\u001b[0m)               â (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m64\u001b[0m)     â        \u001b[38;5;34m51,264\u001b[0m â\n",
       "âââââââââââââââââââââââââââââââââââ¼âââââââââââââââââââââââââ¼ââââââââââââââââ¤\n",
       "â batch_normalization_1           â (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m64\u001b[0m)     â           \u001b[38;5;34m256\u001b[0m â\n",
       "â (\u001b[38;5;33mBatchNormalization\u001b[0m)            â                        â               â\n",
       "âââââââââââââââââââââââââââââââââââ¼âââââââââââââââââââââââââ¼ââââââââââââââââ¤\n",
       "â max_pooling2d_1 (\u001b[38;5;33mMaxPooling2D\u001b[0m)  â (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m64\u001b[0m)     â             \u001b[38;5;34m0\u001b[0m â\n",
       "âââââââââââââââââââââââââââââââââââ¼âââââââââââââââââââââââââ¼ââââââââââââââââ¤\n",
       "â conv2d_2 (\u001b[38;5;33mConv2D\u001b[0m)               â (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m128\u001b[0m)    â        \u001b[38;5;34m73,856\u001b[0m â\n",
       "âââââââââââââââââââââââââââââââââââ¼âââââââââââââââââââââââââ¼ââââââââââââââââ¤\n",
       "â batch_normalization_2           â (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m128\u001b[0m)    â           \u001b[38;5;34m512\u001b[0m â\n",
       "â (\u001b[38;5;33mBatchNormalization\u001b[0m)            â                        â               â\n",
       "âââââââââââââââââââââââââââââââââââ¼âââââââââââââââââââââââââ¼ââââââââââââââââ¤\n",
       "â conv2d_3 (\u001b[38;5;33mConv2D\u001b[0m)               â (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m128\u001b[0m)    â       \u001b[38;5;34m147,584\u001b[0m â\n",
       "âââââââââââââââââââââââââââââââââââ¼âââââââââââââââââââââââââ¼ââââââââââââââââ¤\n",
       "â batch_normalization_3           â (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m128\u001b[0m)    â           \u001b[38;5;34m512\u001b[0m â\n",
       "â (\u001b[38;5;33mBatchNormalization\u001b[0m)            â                        â               â\n",
       "âââââââââââââââââââââââââââââââââââ¼âââââââââââââââââââââââââ¼ââââââââââââââââ¤\n",
       "â max_pooling2d_2 (\u001b[38;5;33mMaxPooling2D\u001b[0m)  â (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m128\u001b[0m)      â             \u001b[38;5;34m0\u001b[0m â\n",
       "âââââââââââââââââââââââââââââââââââ¼âââââââââââââââââââââââââ¼ââââââââââââââââ¤\n",
       "â conv2d_4 (\u001b[38;5;33mConv2D\u001b[0m)               â (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m256\u001b[0m)      â       \u001b[38;5;34m295,168\u001b[0m â\n",
       "âââââââââââââââââââââââââââââââââââ¼âââââââââââââââââââââââââ¼ââââââââââââââââ¤\n",
       "â batch_normalization_4           â (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m256\u001b[0m)      â         \u001b[38;5;34m1,024\u001b[0m â\n",
       "â (\u001b[38;5;33mBatchNormalization\u001b[0m)            â                        â               â\n",
       "âââââââââââââââââââââââââââââââââââ¼âââââââââââââââââââââââââ¼ââââââââââââââââ¤\n",
       "â conv2d_5 (\u001b[38;5;33mConv2D\u001b[0m)               â (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m256\u001b[0m)      â       \u001b[38;5;34m590,080\u001b[0m â\n",
       "âââââââââââââââââââââââââââââââââââ¼âââââââââââââââââââââââââ¼ââââââââââââââââ¤\n",
       "â batch_normalization_5           â (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m256\u001b[0m)      â         \u001b[38;5;34m1,024\u001b[0m â\n",
       "â (\u001b[38;5;33mBatchNormalization\u001b[0m)            â                        â               â\n",
       "âââââââââââââââââââââââââââââââââââ¼âââââââââââââââââââââââââ¼ââââââââââââââââ¤\n",
       "â max_pooling2d_3 (\u001b[38;5;33mMaxPooling2D\u001b[0m)  â (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m256\u001b[0m)      â             \u001b[38;5;34m0\u001b[0m â\n",
       "âââââââââââââââââââââââââââââââââââ¼âââââââââââââââââââââââââ¼ââââââââââââââââ¤\n",
       "â conv2d_6 (\u001b[38;5;33mConv2D\u001b[0m)               â (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m256\u001b[0m)      â        \u001b[38;5;34m65,792\u001b[0m â\n",
       "âââââââââââââââââââââââââââââââââââ¼âââââââââââââââââââââââââ¼ââââââââââââââââ¤\n",
       "â batch_normalization_6           â (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m256\u001b[0m)      â         \u001b[38;5;34m1,024\u001b[0m â\n",
       "â (\u001b[38;5;33mBatchNormalization\u001b[0m)            â                        â               â\n",
       "âââââââââââââââââââââââââââââââââââ¼âââââââââââââââââââââââââ¼ââââââââââââââââ¤\n",
       "â global_average_pooling2d        â (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            â             \u001b[38;5;34m0\u001b[0m â\n",
       "â (\u001b[38;5;33mGlobalAveragePooling2D\u001b[0m)        â                        â               â\n",
       "âââââââââââââââââââââââââââââââââââ¼âââââââââââââââââââââââââ¼ââââââââââââââââ¤\n",
       "â dense (\u001b[38;5;33mDense\u001b[0m)                   â (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)            â       \u001b[38;5;34m131,584\u001b[0m â\n",
       "âââââââââââââââââââââââââââââââââââ¼âââââââââââââââââââââââââ¼ââââââââââââââââ¤\n",
       "â l2_normalization                â (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)            â             \u001b[38;5;34m0\u001b[0m â\n",
       "â (\u001b[38;5;33mL2Normalization\u001b[0m)               â                        â               â\n",
       "âââââââââââââââââââââââââââââââââââ¼âââââââââââââââââââââââââ¼ââââââââââââââââ¤\n",
       "â dropout (\u001b[38;5;33mDropout\u001b[0m)               â (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)            â             \u001b[38;5;34m0\u001b[0m â\n",
       "âââââââââââââââââââââââââââââââââââ´âââââââââââââââââââââââââ´ââââââââââââââââ\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,364,544</span> (5.21 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m1,364,544\u001b[0m (5.21 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,362,304</span> (5.20 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m1,362,304\u001b[0m (5.20 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,240</span> (8.75 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m2,240\u001b[0m (8.75 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def build_embedding_network(input_shape=(256, 256, 3), embedding_dim=512):\n",
    "    inputs = layers.Input(shape=input_shape)\n",
    "\n",
    "    # Feature extraction block\n",
    "    x = layers.Conv2D(32, (7, 7), strides=2, padding='same', activation='relu')(inputs)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.MaxPooling2D((3, 3), strides=2, padding='same')(x)\n",
    "\n",
    "    # Second block\n",
    "    x = layers.Conv2D(64, (5, 5), strides=2, padding='same', activation='relu')(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.MaxPooling2D((3, 3), strides=2, padding='same')(x)\n",
    "\n",
    "    # Third block\n",
    "    x = layers.Conv2D(128, (3, 3), strides=1, padding='same', activation='relu')(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Conv2D(128, (3, 3), strides=1, padding='same', activation='relu')(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.MaxPooling2D((2, 2), strides=2, padding='same')(x)\n",
    "    \n",
    "    # Feature extraction block 4 (Additional deeper block)\n",
    "    x = layers.Conv2D(256, (3, 3), strides=1, padding='same', activation='relu')(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Conv2D(256, (3, 3), strides=1, padding='same', activation='relu')(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.MaxPooling2D((2, 2), strides=2, padding='same')(x)\n",
    "    \n",
    "    # Bottleneck and global pooling\n",
    "    x = layers.Conv2D(256, (1, 1), activation='relu', kernel_regularizer=regularizers.l2(0.01))(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.GlobalAveragePooling2D()(x)\n",
    "\n",
    "    # Dense layers for embedding\n",
    "    x = layers.Dense(embedding_dim, activation='relu')(x)\n",
    "    x = L2Normalization()(x)\n",
    "\n",
    "    # Add dropout to prevent overfitting\n",
    "    x = layers.Dropout(0.5)(x)\n",
    "\n",
    "    # Create the model\n",
    "    model = models.Model(inputs, x, name=\"EmbeddingNetwork\")\n",
    "    return model\n",
    "\n",
    "# Build the model\n",
    "embedding_model = build_embedding_network()\n",
    "embedding_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"LabelPredictor\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"LabelPredictor\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">âââââââââââââââââââââââââââââââââââ³âââââââââââââââââââââââââ³ââââââââââââââââ\n",
       "â<span style=\"font-weight: bold\"> Layer (type)                    </span>â<span style=\"font-weight: bold\"> Output Shape           </span>â<span style=\"font-weight: bold\">       Param # </span>â\n",
       "â¡âââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââ©\n",
       "â input_layer_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)      â (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)    â             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â\n",
       "âââââââââââââââââââââââââââââââââââ¼âââââââââââââââââââââââââ¼ââââââââââââââââ¤\n",
       "â EmbeddingNetwork (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Functional</span>)   â (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            â     <span style=\"color: #00af00; text-decoration-color: #00af00\">1,364,544</span> â\n",
       "âââââââââââââââââââââââââââââââââââ¼âââââââââââââââââââââââââ¼ââââââââââââââââ¤\n",
       "â dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 â (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">107</span>)            â        <span style=\"color: #00af00; text-decoration-color: #00af00\">54,891</span> â\n",
       "âââââââââââââââââââââââââââââââââââ´âââââââââââââââââââââââââ´ââââââââââââââââ\n",
       "</pre>\n"
      ],
      "text/plain": [
       "âââââââââââââââââââââââââââââââââââ³âââââââââââââââââââââââââ³ââââââââââââââââ\n",
       "â\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0mâ\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0mâ\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0mâ\n",
       "â¡âââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââ©\n",
       "â input_layer_1 (\u001b[38;5;33mInputLayer\u001b[0m)      â (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m3\u001b[0m)    â             \u001b[38;5;34m0\u001b[0m â\n",
       "âââââââââââââââââââââââââââââââââââ¼âââââââââââââââââââââââââ¼ââââââââââââââââ¤\n",
       "â EmbeddingNetwork (\u001b[38;5;33mFunctional\u001b[0m)   â (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)            â     \u001b[38;5;34m1,364,544\u001b[0m â\n",
       "âââââââââââââââââââââââââââââââââââ¼âââââââââââââââââââââââââ¼ââââââââââââââââ¤\n",
       "â dense_1 (\u001b[38;5;33mDense\u001b[0m)                 â (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m107\u001b[0m)            â        \u001b[38;5;34m54,891\u001b[0m â\n",
       "âââââââââââââââââââââââââââââââââââ´âââââââââââââââââââââââââ´ââââââââââââââââ\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,419,435</span> (5.41 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m1,419,435\u001b[0m (5.41 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,417,195</span> (5.41 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m1,417,195\u001b[0m (5.41 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,240</span> (8.75 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m2,240\u001b[0m (8.75 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def build_label_predictor(embedding_model, num_classes, input_shape=(256,256,3)):\n",
    "    embedding_model = embedding_model\n",
    "    \n",
    "    inputs = Input(shape=input_shape)\n",
    "    embedding = embedding_model(inputs)\n",
    "    outputs = layers.Dense(num_classes, activation='softmax')(embedding)\n",
    "    \n",
    "    model = models.Model(inputs, outputs, name=\"LabelPredictor\")\n",
    "    return model\n",
    "\n",
    "predictor_model = build_label_predictor(embedding_model, 107)\n",
    "predictor_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1738072503.215759 1855439 service.cc:146] XLA service 0x7efc5c01e330 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "I0000 00:00:1738072503.215812 1855439 service.cc:154]   StreamExecutor device (0): NVIDIA GeForce RTX 3050 Laptop GPU, Compute Capability 8.6\n",
      "2025-01-28 14:55:03.360823: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:268] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2025-01-28 14:55:04.084088: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:531] Loaded cuDNN version 8907\n",
      "2025-01-28 14:55:06.105116: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:393] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_2270', 12 bytes spill stores, 12 bytes spill loads\n",
      "\n",
      "2025-01-28 14:55:09.846505: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:393] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_3600', 436 bytes spill stores, 436 bytes spill loads\n",
      "\n",
      "2025-01-28 14:55:10.054033: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:393] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_3600', 492 bytes spill stores, 492 bytes spill loads\n",
      "\n",
      "2025-01-28 14:55:10.426356: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:393] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_2930', 1052 bytes spill stores, 1052 bytes spill loads\n",
      "\n",
      "I0000 00:00:1738072522.277848 1855439 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m287/287\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m434s\u001b[0m 1s/step - accuracy: 0.0241 - auc: 0.5470 - loss: 5.4738 - top_k_categorical_accuracy: 0.0666 - val_accuracy: 0.0211 - val_auc: 0.5539 - val_loss: 4.6645 - val_top_k_categorical_accuracy: 0.0478\n",
      "Epoch 2/50\n",
      "\u001b[1m287/287\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m314s\u001b[0m 1s/step - accuracy: 0.0505 - auc: 0.6540 - loss: 4.4797 - top_k_categorical_accuracy: 0.1142 - val_accuracy: 0.0303 - val_auc: 0.5477 - val_loss: 4.7213 - val_top_k_categorical_accuracy: 0.0781\n",
      "Epoch 3/50\n",
      "\u001b[1m287/287\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m268s\u001b[0m 932ms/step - accuracy: 0.0568 - auc: 0.6942 - loss: 4.3939 - top_k_categorical_accuracy: 0.1292 - val_accuracy: 0.0662 - val_auc: 0.6983 - val_loss: 4.3708 - val_top_k_categorical_accuracy: 0.1425\n",
      "Epoch 4/50\n",
      "\u001b[1m 89/287\u001b[0m \u001b[32mââââââ\u001b[0m\u001b[37mââââââââââââââ\u001b[0m \u001b[1m2:54\u001b[0m 879ms/step - accuracy: 0.0667 - auc: 0.7098 - loss: 4.3435 - top_k_categorical_accuracy: 0.1484"
     ]
    }
   ],
   "source": [
    "predictor_model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy',tf.keras.metrics.AUC(), tf.keras.metrics.TopKCategoricalAccuracy(k=3) ])\n",
    "\n",
    "early = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=5, verbose=1, restore_best_weights=True)\n",
    "\n",
    "predictor_model.fit(train_gen, validation_data=val_gen, epochs=50, callbacks=[early])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loss, test_acc, _,_ = predictor_model.evaluate(test_gen)\n",
    "\n",
    "print(\"Test accuracy: {:.2f}%\".format(test_acc * 100))\n",
    "print(\"Test loss: {:.2f}\".format(test_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_model.save(\"Models_Final/embedding_final.keras\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "CV2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
