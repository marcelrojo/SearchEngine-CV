{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import random\n",
    "import numpy as np\n",
    "import glob\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from PIL import Image as PILImage\n",
    "from PIL.ExifTags import TAGS\n",
    "\n",
    "from IPython.display import display\n",
    "\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.applications import ResNet50\n",
    "from keras_resnet.models import ResNet18 \n",
    "from tensorflow.keras.utils import Sequence\n",
    "from tensorflow.keras.layers import Input\n",
    "from tensorflow.keras import regularizers\n",
    "\n",
    "from keras.layers import Layer\n",
    "\n",
    "from tensorflow.keras.models import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 32\n",
    "IMAGE_SIZE = (256, 256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def imshow(a, size=1.0):\n",
    "    # Clip and convert the image to uint8\n",
    "    a = a.clip(0, 255).astype(\"uint8\")\n",
    "    \n",
    "    # Resize the image if a size factor is provided\n",
    "    if size != 1.0:\n",
    "        new_dim = (int(a.shape[1] * size), int(a.shape[0] * size))\n",
    "        a = cv2.resize(a, new_dim, interpolation=cv2.INTER_AREA)\n",
    "    \n",
    "    \n",
    "    # Display the image\n",
    "    display(PILImage.fromarray(a))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_label(file_path):\n",
    "    label = file_path.split(\"/\")[-2]\n",
    "    label = label.split(\".\")[-2]\n",
    "    label = int(label)\n",
    "    return label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_image(file_path):\n",
    "    img = cv2.imread(file_path)\n",
    "    img = cv2.resize(img, IMAGE_SIZE)\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_triplets(file_paths, labels):\n",
    "    label_to_indices = {}\n",
    "    for idx, label in enumerate(labels):\n",
    "        if label not in label_to_indices:\n",
    "            label_to_indices[label] = []\n",
    "        label_to_indices[label].append(idx)\n",
    "    \n",
    "    triplets = []\n",
    "    \n",
    "    for i in range(len(file_paths)):\n",
    "        # Select an anchor image and its label\n",
    "        anchor_idx = i\n",
    "        anchor_label = labels[anchor_idx]\n",
    "\n",
    "        # Select a positive image (same label)\n",
    "        positive_idx = random.choice(label_to_indices[anchor_label])\n",
    "        while positive_idx == anchor_idx:\n",
    "            positive_idx = random.choice(label_to_indices[anchor_label])\n",
    "\n",
    "        # Select a negative image (different label)\n",
    "        negative_label = random.choice([l for l in label_to_indices.keys() if l != anchor_label])\n",
    "        negative_idx = random.choice(label_to_indices[negative_label])\n",
    "\n",
    "        triplets.append((file_paths[anchor_idx], file_paths[positive_idx], file_paths[negative_idx]))\n",
    "    \n",
    "    random.shuffle(triplets)\n",
    "    return triplets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataGenerator(Sequence):\n",
    "    def __init__(self, triplets, batch_size, image_size, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.triplets = triplets\n",
    "        self.batch_size = batch_size\n",
    "        self.image_size = image_size\n",
    "      \n",
    "    def __len__(self):\n",
    "        return len(self.triplets) // self.batch_size\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        # Get batch of triplets\n",
    "        batch_triplets = self.triplets[index * self.batch_size : (index + 1) * self.batch_size]\n",
    "        \n",
    "        # Prepare arrays for images\n",
    "        anchors, positives, negatives = [], [], []\n",
    "        for anchor_path, positive_path, negative_path in batch_triplets:\n",
    "            # Load and normalize images\n",
    "            anchors.append(read_image(anchor_path) / 255.0)\n",
    "            positives.append(read_image(positive_path) / 255.0)\n",
    "            negatives.append(read_image(negative_path) / 255.0)\n",
    "\n",
    "        # Convert lists to arrays and return\n",
    "        anchors = np.array(anchors)\n",
    "        positives = np.array(positives)\n",
    "        negatives = np.array(negatives)\n",
    "        \n",
    "     \n",
    "        \n",
    "        #print(f\"Anchors shape: {anchors.shape}, Positives shape: {positives.shape}, Negatives shape: {negatives.shape}\")\n",
    "        return (anchors, positives, negatives), np.zeros((self.batch_size, 1))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_folder = \"Data/*\"\n",
    "image_files = glob.glob(os.path.join(data_folder, \"*.jpg\"), recursive=True)\n",
    "\n",
    "labels = [get_label(file_path) for file_path in image_files]\n",
    "\n",
    "train_x, val_x, train_y, val_y = train_test_split(image_files, labels, test_size=0.1, random_state=42, stratify=labels)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_triplets = generate_triplets(train_x, train_y)\n",
    "val_triplets = generate_triplets(val_x, val_y)\n",
    "\n",
    "train_gen = DataGenerator(train_triplets, batch_size=BATCH_SIZE, image_size=(256, 256, 3))\n",
    "val_gen = DataGenerator(val_triplets, batch_size=BATCH_SIZE, image_size=(256, 256, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "class L2Normalization(Layer):\n",
    "    def call(self, inputs):\n",
    "        return tf.math.l2_normalize(inputs, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_embedding_network(input_shape=(256, 256, 3), embedding_dim=512):\n",
    "    inputs = layers.Input(shape=input_shape)\n",
    "\n",
    "    # Feature extraction block\n",
    "    x = layers.Conv2D(32, (7, 7), strides=2, padding='same', activation='relu')(inputs)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.MaxPooling2D((3, 3), strides=2, padding='same')(x)\n",
    "\n",
    "    # Second block\n",
    "    x = layers.Conv2D(64, (5, 5), strides=2, padding='same', activation='relu')(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.MaxPooling2D((3, 3), strides=2, padding='same')(x)\n",
    "\n",
    "    # Third block\n",
    "    x = layers.Conv2D(128, (3, 3), strides=1, padding='same', activation='relu')(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Conv2D(128, (3, 3), strides=1, padding='same', activation='relu')(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.MaxPooling2D((2, 2), strides=2, padding='same')(x)\n",
    "    \n",
    "    # Feature extraction block 4 (Additional deeper block)\n",
    "    x = layers.Conv2D(256, (3, 3), strides=1, padding='same', activation='relu')(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Conv2D(256, (3, 3), strides=1, padding='same', activation='relu')(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.MaxPooling2D((2, 2), strides=2, padding='same')(x)\n",
    "    \n",
    "     # Feature extraction block 5 (Even deeper block)\n",
    "    x = layers.Conv2D(512, (3, 3), strides=1, padding='same', activation='relu')(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Conv2D(512, (3, 3), strides=1, padding='same', activation='relu')(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.MaxPooling2D((2, 2), strides=2, padding='same')(x)\n",
    "\n",
    "    # Bottleneck and global pooling\n",
    "    x = layers.Conv2D(1024, (1, 1), activation='relu', kernel_regularizer=regularizers.l2(0.01))(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.GlobalAveragePooling2D()(x)\n",
    "\n",
    "    # Dense layers for embedding\n",
    "    x = layers.Dense(embedding_dim, activation='relu')(x)\n",
    "    x = L2Normalization()(x)\n",
    "\n",
    "    # Add dropout to prevent overfitting\n",
    "    x = layers.Dropout(0.5)(x)\n",
    "\n",
    "    # Create the model\n",
    "    model = models.Model(inputs, x, name=\"EmbeddingNetwork\")\n",
    "    return model\n",
    "\n",
    "# Build the model\n",
    "embedding_model = load_model(\"Models/embedding_extractor_custom_big.keras\",\n",
    "                             custom_objects={\"L2Normalization\": L2Normalization})\n",
    "embedding_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_siamese_model_with_resnet(embedding_model, input_shape=(256, 256, 3)):\n",
    "    # Inputs for anchor, positive, and negative images\n",
    "    anchor_input = layers.Input(name=\"anchor\", shape=input_shape)\n",
    "    positive_input = layers.Input(name=\"positive\", shape=input_shape)\n",
    "    negative_input = layers.Input(name=\"negative\", shape=input_shape)\n",
    "    \n",
    "\n",
    "    # Pass each input through the embedding network\n",
    "    anchor_embedding = embedding_model(anchor_input)\n",
    "    positive_embedding = embedding_model(positive_input)\n",
    "    negative_embedding = embedding_model(negative_input)\n",
    "\n",
    "    embeddings = layers.Lambda(lambda x: tf.concat(x, axis=1))(\n",
    "        [anchor_embedding, positive_embedding, negative_embedding]\n",
    "    )\n",
    "    \n",
    "    # Combine embeddings into a Siamese model\n",
    "    siamese_model = models.Model(\n",
    "        inputs=[anchor_input, positive_input, negative_input],\n",
    "        outputs=embeddings\n",
    "    )\n",
    "\n",
    "    return siamese_model\n",
    "\n",
    "siamese_model = build_siamese_model_with_resnet(embedding_model)\n",
    "siamese_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def triplet_loss(y_true, y_pred, margin=0.2):\n",
    "    # Split y_pred into anchor, positive, and negative\n",
    "    anchor, positive, negative = tf.split(y_pred, num_or_size_splits=3, axis=1)\n",
    "    \n",
    "    # # Compute distances\n",
    "    pos_similarity = tf.reduce_sum(anchor * positive, axis=1)  # Dot product\n",
    "    neg_similarity = tf.reduce_sum(anchor * negative, axis=1)\n",
    "    \n",
    "    # Convert similarity to distance\n",
    "    pos_dist = 1 - pos_similarity\n",
    "    neg_dist = 1 - neg_similarity\n",
    "    \n",
    "\n",
    "    # # Compute triplet loss\n",
    "    loss = tf.maximum(pos_dist - neg_dist + margin, 0.0)\n",
    "    return tf.reduce_mean(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "siamese_model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=1e-6), loss=triplet_loss)\n",
    "\n",
    "early = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=5, verbose=1, restore_best_weights=True)\n",
    "\n",
    "# Train the model\n",
    "siamese_model.fit(\n",
    "    train_gen,\n",
    "    validation_data=val_gen,\n",
    "    epochs=50,\n",
    "    callbacks=[early]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#siamese_model.save(\"siamese_resnet_model.keras\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_model.save(\"Models/transfer_custom_big_2.keras\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "CV2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
