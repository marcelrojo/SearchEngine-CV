{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import math\n",
    "import cv2\n",
    "import PIL\n",
    "import os\n",
    "import sys\n",
    "import glob\n",
    "import random\n",
    "\n",
    "from PIL import Image as PILImage\n",
    "from PIL.ExifTags import TAGS\n",
    "\n",
    "from IPython.display import display\n",
    "\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.applications import ResNet50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def imshow(a, size=1.0):\n",
    "    # Clip and convert the image to uint8\n",
    "    a = a.clip(0, 255).astype(\"uint8\")\n",
    "    \n",
    "    # Resize the image if a size factor is provided\n",
    "    if size != 1.0:\n",
    "        new_dim = (int(a.shape[1] * size), int(a.shape[0] * size))\n",
    "        a = cv2.resize(a, new_dim, interpolation=cv2.INTER_AREA)\n",
    "    \n",
    "    # Convert color format if needed\n",
    "    # if a.ndim == 3:\n",
    "    #     if a.shape[2] == 4:\n",
    "    #         a = cv2.cvtColor(a, cv2.COLOR_BGRA2RGBA)\n",
    "    #     else:\n",
    "    #         a = cv2.cvtColor(a, cv2.COLOR_BGR2RGB)\n",
    "    \n",
    "    # Display the image\n",
    "    display(PIL.Image.fromarray(a))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preproccess(image):\n",
    "    image = cv2.resize(image, (256, 256))\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1151 1151\n"
     ]
    }
   ],
   "source": [
    "data_folder = \"Data/00*\"\n",
    "image_files = glob.glob(os.path.join(data_folder, \"*.jpg\"), recursive=True)\n",
    "\n",
    "\n",
    "data_x = []\n",
    "data_y = []\n",
    "\n",
    "for image_file in image_files:\n",
    "    image = cv2.imread(image_file)\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    image = preproccess(image)\n",
    "    \n",
    "    label = image_file.split(\"/\")[-2]\n",
    "    label = label.split(\".\")[-2]\n",
    "    label = int(label)\n",
    "    \n",
    "    data_x.append(image)\n",
    "    data_y.append(label)\n",
    "\n",
    "print(len(data_x), len(data_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(image, label):\n",
    "    # Perform preprocessing on the image\n",
    "    image = tf.image.resize(image, [256, 256])  # Resize to 256x256\n",
    "    image = tf.cast(image, tf.float32) / 255.0  # Normalize to [0, 1]\n",
    "    return image, label\n",
    "\n",
    "# Augmentation function\n",
    "def augment(image, label):\n",
    "    # Apply augmentations in [0, 1]\n",
    "    image = tf.image.random_flip_left_right(image)\n",
    "    image = tf.image.random_flip_up_down(image)\n",
    "    image = tf.image.rot90(image, k=tf.random.uniform([], 0, 4, dtype=tf.int32))\n",
    "    image = tf.image.random_brightness(image, max_delta=0.2)\n",
    "    image = tf.image.random_contrast(image, lower=0.8, upper=1.2)\n",
    "    image = tf.image.random_hue(image, max_delta=0.1)\n",
    "    image = tf.image.random_saturation(image, lower=0.9, upper=1.1)\n",
    "    noise = tf.random.normal(shape=tf.shape(image), mean=0.0, stddev=0.02, dtype=tf.float32)\n",
    "    image = tf.add(image, noise)\n",
    "    image = tf.clip_by_value(image, 0.0, 1.0)  # Ensure valid pixel range\n",
    "    return image, label\n",
    "\n",
    "# Data loading function\n",
    "def load_data(filepaths, labels, batch_size=32):\n",
    "    def parse_function(filepath, label):\n",
    "        image = tf.io.read_file(filepath)\n",
    "        image = tf.image.decode_jpeg(image, channels=3)\n",
    "        image = tf.image.resize(image, [256, 256])  # Ensure consistent shape\n",
    "        return image, label\n",
    "\n",
    "    # Create dataset\n",
    "    dataset = tf.data.Dataset.from_tensor_slices((filepaths, labels))\n",
    "    dataset = dataset.map(parse_function, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "    dataset = dataset.map(preprocess, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "    dataset = dataset.map(augment, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "    dataset = dataset.shuffle(buffer_size=1000).batch(batch_size).prefetch(buffer_size=tf.data.AUTOTUNE)\n",
    "\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set size: 920\n",
      "Validation set size: 231\n"
     ]
    }
   ],
   "source": [
    "train_x, val_x, train_y, val_y = train_test_split(\n",
    "    data_x, data_y, test_size=0.2, random_state=42, stratify=data_y\n",
    ")\n",
    "\n",
    "print(f\"Training set size: {len(train_x)}\")\n",
    "print(f\"Validation set size: {len(val_x)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_triplets(images, labels, num_triplets=10000):\n",
    "    label_to_indices = {label: np.where(np.array(labels) == label)[0] for label in np.unique(labels)}\n",
    "    \n",
    "    triplets = []\n",
    "    for _ in range(num_triplets):\n",
    "        # Select an anchor image and its label\n",
    "        anchor_idx = random.choice(range(len(images)))\n",
    "        anchor_label = labels[anchor_idx]\n",
    "\n",
    "        # Select a positive image (same label)\n",
    "        positive_idx = random.choice(label_to_indices[anchor_label])\n",
    "        while positive_idx == anchor_idx:\n",
    "            positive_idx = random.choice(label_to_indices[anchor_label])\n",
    "\n",
    "        # Select a negative image (different label)\n",
    "        negative_label = random.choice([l for l in label_to_indices.keys() if l != anchor_label])\n",
    "        negative_idx = random.choice(label_to_indices[negative_label])\n",
    "\n",
    "        triplets.append((images[anchor_idx], images[positive_idx], images[negative_idx]))\n",
    "    \n",
    "    return triplets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_triplets(triplets):\n",
    "    for anchor, positive, negative in triplets[:5]:\n",
    "        print(\"Anchor:\")\n",
    "        imshow(anchor)\n",
    "        print(\"Positive:\")\n",
    "        imshow(positive)\n",
    "        print(\"Negative:\")\n",
    "        imshow(negative)\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_triplets = generate_triplets(train_x, train_y, num_triplets=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-24 18:16:53.591035: W external/local_tsl/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 786432000 exceeds 10% of free system memory.\n",
      "2025-01-24 18:18:04.090668: W external/local_tsl/tsl/framework/bfc_allocator.cc:482] Allocator (GPU_0_bfc) ran out of memory trying to allocate 750.00MiB (rounded to 786432000)requested by op RealDiv\n",
      "If the cause is memory fragmentation maybe the environment variable 'TF_GPU_ALLOCATOR=cuda_malloc_async' will improve the situation. \n",
      "Current allocation summary follows.\n",
      "Current allocation summary follows.\n",
      "2025-01-24 18:18:04.090903: I external/local_tsl/tsl/framework/bfc_allocator.cc:1039] BFCAllocator dump for GPU_0_bfc\n",
      "2025-01-24 18:18:04.091267: I external/local_tsl/tsl/framework/bfc_allocator.cc:1046] Bin (256): \tTotal Chunks: 21, Chunks in use: 21. 5.2KiB allocated for chunks. 5.2KiB in use in bin. 489B client-requested in use in bin.\n",
      "2025-01-24 18:18:04.091367: I external/local_tsl/tsl/framework/bfc_allocator.cc:1046] Bin (512): \tTotal Chunks: 2, Chunks in use: 2. 1.0KiB allocated for chunks. 1.0KiB in use in bin. 1.0KiB client-requested in use in bin.\n",
      "2025-01-24 18:18:04.091379: I external/local_tsl/tsl/framework/bfc_allocator.cc:1046] Bin (1024): \tTotal Chunks: 1, Chunks in use: 1. 1.2KiB allocated for chunks. 1.2KiB in use in bin. 1.0KiB client-requested in use in bin.\n",
      "2025-01-24 18:18:04.091394: I external/local_tsl/tsl/framework/bfc_allocator.cc:1046] Bin (2048): \tTotal Chunks: 1, Chunks in use: 1. 3.5KiB allocated for chunks. 3.5KiB in use in bin. 3.4KiB client-requested in use in bin.\n",
      "2025-01-24 18:18:04.091413: I external/local_tsl/tsl/framework/bfc_allocator.cc:1046] Bin (4096): \tTotal Chunks: 1, Chunks in use: 0. 4.5KiB allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2025-01-24 18:18:04.091423: I external/local_tsl/tsl/framework/bfc_allocator.cc:1046] Bin (8192): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2025-01-24 18:18:04.091431: I external/local_tsl/tsl/framework/bfc_allocator.cc:1046] Bin (16384): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2025-01-24 18:18:04.091437: I external/local_tsl/tsl/framework/bfc_allocator.cc:1046] Bin (32768): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2025-01-24 18:18:04.091446: I external/local_tsl/tsl/framework/bfc_allocator.cc:1046] Bin (65536): \tTotal Chunks: 2, Chunks in use: 2. 136.0KiB allocated for chunks. 136.0KiB in use in bin. 136.0KiB client-requested in use in bin.\n",
      "2025-01-24 18:18:04.091453: I external/local_tsl/tsl/framework/bfc_allocator.cc:1046] Bin (131072): \tTotal Chunks: 1, Chunks in use: 0. 144.0KiB allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2025-01-24 18:18:04.091461: I external/local_tsl/tsl/framework/bfc_allocator.cc:1046] Bin (262144): \tTotal Chunks: 1, Chunks in use: 1. 288.0KiB allocated for chunks. 288.0KiB in use in bin. 288.0KiB client-requested in use in bin.\n",
      "2025-01-24 18:18:04.091467: I external/local_tsl/tsl/framework/bfc_allocator.cc:1046] Bin (524288): \tTotal Chunks: 1, Chunks in use: 0. 512.0KiB allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2025-01-24 18:18:04.091474: I external/local_tsl/tsl/framework/bfc_allocator.cc:1046] Bin (1048576): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2025-01-24 18:18:04.091479: I external/local_tsl/tsl/framework/bfc_allocator.cc:1046] Bin (2097152): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2025-01-24 18:18:04.091485: I external/local_tsl/tsl/framework/bfc_allocator.cc:1046] Bin (4194304): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2025-01-24 18:18:04.091491: I external/local_tsl/tsl/framework/bfc_allocator.cc:1046] Bin (8388608): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2025-01-24 18:18:04.091497: I external/local_tsl/tsl/framework/bfc_allocator.cc:1046] Bin (16777216): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2025-01-24 18:18:04.091504: I external/local_tsl/tsl/framework/bfc_allocator.cc:1046] Bin (33554432): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2025-01-24 18:18:04.091511: I external/local_tsl/tsl/framework/bfc_allocator.cc:1046] Bin (67108864): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2025-01-24 18:18:04.091520: I external/local_tsl/tsl/framework/bfc_allocator.cc:1046] Bin (134217728): \tTotal Chunks: 4, Chunks in use: 3. 748.93MiB allocated for chunks. 562.50MiB in use in bin. 562.50MiB client-requested in use in bin.\n",
      "2025-01-24 18:18:04.091529: I external/local_tsl/tsl/framework/bfc_allocator.cc:1046] Bin (268435456): \tTotal Chunks: 2, Chunks in use: 1. 1017.40MiB allocated for chunks. 750.00MiB in use in bin. 750.00MiB client-requested in use in bin.\n",
      "2025-01-24 18:18:04.091576: I external/local_tsl/tsl/framework/bfc_allocator.cc:1062] Bin for 750.00MiB was 256.00MiB, Chunk State: \n",
      "2025-01-24 18:18:04.091684: I external/local_tsl/tsl/framework/bfc_allocator.cc:1068]   Size: 267.40MiB | Requested Size: 0B | in_use: 0 | bin_num: 20, prev:   Size: 187.50MiB | Requested Size: 187.50MiB | in_use: 1 | bin_num: -1\n",
      "2025-01-24 18:18:04.091733: I external/local_tsl/tsl/framework/bfc_allocator.cc:1075] Next region of size 1853253120\n",
      "2025-01-24 18:18:04.091822: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 503e00000 of size 1280 next 1\n",
      "2025-01-24 18:18:04.091836: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 503e00500 of size 256 next 2\n",
      "2025-01-24 18:18:04.091842: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 503e00600 of size 256 next 3\n",
      "2025-01-24 18:18:04.091849: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 503e00700 of size 256 next 4\n",
      "2025-01-24 18:18:04.091855: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 503e00800 of size 256 next 5\n",
      "2025-01-24 18:18:04.091860: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 503e00900 of size 256 next 6\n",
      "2025-01-24 18:18:04.091866: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 503e00a00 of size 256 next 7\n",
      "2025-01-24 18:18:04.091872: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 503e00b00 of size 256 next 13\n",
      "2025-01-24 18:18:04.091877: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 503e00c00 of size 256 next 14\n",
      "2025-01-24 18:18:04.091883: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 503e00d00 of size 256 next 15\n",
      "2025-01-24 18:18:04.091889: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 503e00e00 of size 256 next 16\n",
      "2025-01-24 18:18:04.091894: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 503e00f00 of size 256 next 17\n",
      "2025-01-24 18:18:04.091901: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 503e01000 of size 256 next 19\n",
      "2025-01-24 18:18:04.091907: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 503e01100 of size 256 next 20\n",
      "2025-01-24 18:18:04.091912: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 503e01200 of size 256 next 18\n",
      "2025-01-24 18:18:04.091918: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 503e01300 of size 256 next 21\n",
      "2025-01-24 18:18:04.091923: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 503e01400 of size 256 next 26\n",
      "2025-01-24 18:18:04.091929: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 503e01500 of size 256 next 24\n",
      "2025-01-24 18:18:04.091935: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 503e01600 of size 512 next 25\n",
      "2025-01-24 18:18:04.091941: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 503e01800 of size 256 next 31\n",
      "2025-01-24 18:18:04.091946: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 503e01900 of size 256 next 29\n",
      "2025-01-24 18:18:04.091952: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 503e01a00 of size 512 next 30\n",
      "2025-01-24 18:18:04.091958: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 503e01c00 of size 256 next 39\n",
      "2025-01-24 18:18:04.092012: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] Free  at 503e01d00 of size 4608 next 22\n",
      "2025-01-24 18:18:04.092028: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 503e02f00 of size 3584 next 23\n",
      "2025-01-24 18:18:04.092037: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] Free  at 503e03d00 of size 147456 next 28\n",
      "2025-01-24 18:18:04.092043: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 503e27d00 of size 73728 next 27\n",
      "2025-01-24 18:18:04.092078: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 503e39d00 of size 65536 next 37\n",
      "2025-01-24 18:18:04.092086: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] Free  at 503e49d00 of size 524288 next 33\n",
      "2025-01-24 18:18:04.092092: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 503ec9d00 of size 294912 next 32\n",
      "2025-01-24 18:18:04.092098: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] Free  at 503f11d00 of size 195489280 next 8\n",
      "2025-01-24 18:18:04.092104: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 50f980b00 of size 256 next 9\n",
      "2025-01-24 18:18:04.092111: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 50f980c00 of size 786432000 next 36\n",
      "2025-01-24 18:18:04.092117: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 53e780c00 of size 196608000 next 34\n",
      "2025-01-24 18:18:04.092123: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 54a300c00 of size 196608000 next 35\n",
      "2025-01-24 18:18:04.092129: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 555e80c00 of size 196608000 next 38\n",
      "2025-01-24 18:18:04.092136: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] Free  at 561a00c00 of size 280386048 next 18446744073709551615\n",
      "2025-01-24 18:18:04.092142: I external/local_tsl/tsl/framework/bfc_allocator.cc:1100]      Summary of in-use Chunks by size: \n",
      "2025-01-24 18:18:04.092153: I external/local_tsl/tsl/framework/bfc_allocator.cc:1103] 21 Chunks of size 256 totalling 5.2KiB\n",
      "2025-01-24 18:18:04.092161: I external/local_tsl/tsl/framework/bfc_allocator.cc:1103] 2 Chunks of size 512 totalling 1.0KiB\n",
      "2025-01-24 18:18:04.092168: I external/local_tsl/tsl/framework/bfc_allocator.cc:1103] 1 Chunks of size 1280 totalling 1.2KiB\n",
      "2025-01-24 18:18:04.092174: I external/local_tsl/tsl/framework/bfc_allocator.cc:1103] 1 Chunks of size 3584 totalling 3.5KiB\n",
      "2025-01-24 18:18:04.092181: I external/local_tsl/tsl/framework/bfc_allocator.cc:1103] 1 Chunks of size 65536 totalling 64.0KiB\n",
      "2025-01-24 18:18:04.092188: I external/local_tsl/tsl/framework/bfc_allocator.cc:1103] 1 Chunks of size 73728 totalling 72.0KiB\n",
      "2025-01-24 18:18:04.092195: I external/local_tsl/tsl/framework/bfc_allocator.cc:1103] 1 Chunks of size 294912 totalling 288.0KiB\n",
      "2025-01-24 18:18:04.092202: I external/local_tsl/tsl/framework/bfc_allocator.cc:1103] 3 Chunks of size 196608000 totalling 562.50MiB\n",
      "2025-01-24 18:18:04.092208: I external/local_tsl/tsl/framework/bfc_allocator.cc:1103] 1 Chunks of size 786432000 totalling 750.00MiB\n",
      "2025-01-24 18:18:04.092216: I external/local_tsl/tsl/framework/bfc_allocator.cc:1107] Sum Total of in-use chunks: 1.28GiB\n",
      "2025-01-24 18:18:04.092222: I external/local_tsl/tsl/framework/bfc_allocator.cc:1109] Total bytes in pool: 1853253120 memory_limit_: 1853253223 available bytes: 103 curr_region_allocation_bytes_: 3706506752\n",
      "2025-01-24 18:18:04.092340: I external/local_tsl/tsl/framework/bfc_allocator.cc:1114] Stats: \n",
      "Limit:                      1853253223\n",
      "InUse:                      1376701440\n",
      "MaxInUse:                   1376701440\n",
      "NumAllocs:                          78\n",
      "MaxAllocSize:                786432000\n",
      "Reserved:                            0\n",
      "PeakReserved:                        0\n",
      "LargestFreeBlock:                    0\n",
      "\n",
      "2025-01-24 18:18:04.092360: W external/local_tsl/tsl/framework/bfc_allocator.cc:494] *_________***************************************************************************_______________\n",
      "2025-01-24 18:18:04.092857: W tensorflow/core/framework/op_kernel.cc:1828] RESOURCE_EXHAUSTED: failed to allocate memory\n",
      "2025-01-24 18:18:04.093106: I tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: RESOURCE_EXHAUSTED: failed to allocate memory\n"
     ]
    },
    {
     "ename": "ResourceExhaustedError",
     "evalue": "{{function_node __wrapped__RealDiv_device_/job:localhost/replica:0/task:0/device:GPU:0}} failed to allocate memory [Op:RealDiv] name: ",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[24], line 21\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;66;03m# Example usage\u001b[39;00m\n\u001b[1;32m     20\u001b[0m batch_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m32\u001b[39m\n\u001b[0;32m---> 21\u001b[0m train_dataset \u001b[38;5;241m=\u001b[39m \u001b[43mcreate_triplet_dataset\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_triplets\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_size\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[24], line 8\u001b[0m, in \u001b[0;36mcreate_triplet_dataset\u001b[0;34m(triplets, batch_size)\u001b[0m\n\u001b[1;32m      5\u001b[0m negatives \u001b[38;5;241m=\u001b[39m [triplet[\u001b[38;5;241m2\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m triplet \u001b[38;5;129;01min\u001b[39;00m triplets]\n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m# Convert to TensorFlow tensors\u001b[39;00m\n\u001b[0;32m----> 8\u001b[0m anchors \u001b[38;5;241m=\u001b[39m \u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconvert_to_tensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43manchors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfloat32\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m255.0\u001b[39;49m  \u001b[38;5;66;03m# Normalize images\u001b[39;00m\n\u001b[1;32m      9\u001b[0m positives \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mconvert_to_tensor(positives, dtype\u001b[38;5;241m=\u001b[39mtf\u001b[38;5;241m.\u001b[39mfloat32) \u001b[38;5;241m/\u001b[39m \u001b[38;5;241m255.0\u001b[39m\n\u001b[1;32m     10\u001b[0m negatives \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mconvert_to_tensor(negatives, dtype\u001b[38;5;241m=\u001b[39mtf\u001b[38;5;241m.\u001b[39mfloat32) \u001b[38;5;241m/\u001b[39m \u001b[38;5;241m255.0\u001b[39m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/tensorflow/python/util/traceback_utils.py:153\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m--> 153\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    154\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    155\u001b[0m   \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/tensorflow/python/framework/ops.py:5983\u001b[0m, in \u001b[0;36mraise_from_not_ok_status\u001b[0;34m(e, name)\u001b[0m\n\u001b[1;32m   5981\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mraise_from_not_ok_status\u001b[39m(e, name) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m NoReturn:\n\u001b[1;32m   5982\u001b[0m   e\u001b[38;5;241m.\u001b[39mmessage \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m name: \u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mstr\u001b[39m(name \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n\u001b[0;32m-> 5983\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_status_to_exception(e) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[0;31mResourceExhaustedError\u001b[0m: {{function_node __wrapped__RealDiv_device_/job:localhost/replica:0/task:0/device:GPU:0}} failed to allocate memory [Op:RealDiv] name: "
     ]
    }
   ],
   "source": [
    "def create_triplet_dataset(triplets, batch_size=32):\n",
    "    # Separate the triplets into anchors, positives, and negatives\n",
    "    anchors = [triplet[0] for triplet in triplets]\n",
    "    positives = [triplet[1] for triplet in triplets]\n",
    "    negatives = [triplet[2] for triplet in triplets]\n",
    "\n",
    "    # Convert to TensorFlow tensors\n",
    "    anchors = tf.convert_to_tensor(anchors, dtype=tf.float32) / 255.0  # Normalize images\n",
    "    positives = tf.convert_to_tensor(positives, dtype=tf.float32) / 255.0\n",
    "    negatives = tf.convert_to_tensor(negatives, dtype=tf.float32) / 255.0\n",
    "\n",
    "    # Create a dataset from the triplets\n",
    "    dataset = tf.data.Dataset.from_tensor_slices((anchors, positives, negatives))\n",
    "    dataset = dataset.shuffle(buffer_size=len(triplets))  # Shuffle for randomness\n",
    "    dataset = dataset.batch(batch_size).prefetch(buffer_size=tf.data.AUTOTUNE)\n",
    "\n",
    "    return dataset\n",
    "\n",
    "# Example usage\n",
    "batch_size = 32\n",
    "train_dataset = create_triplet_dataset(train_triplets, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/marroj/.local/lib/python3.10/site-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">254</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">254</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)   │           <span style=\"color: #00af00; text-decoration-color: #00af00\">896</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">127</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">127</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)   │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">125</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">125</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │        <span style=\"color: #00af00; text-decoration-color: #00af00\">18,496</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">62</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">62</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">60</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">60</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    │        <span style=\"color: #00af00; text-decoration-color: #00af00\">73,856</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ global_average_pooling2d        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePooling2D</span>)        │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">16,512</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lambda (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Lambda</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv2d (\u001b[38;5;33mConv2D\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m254\u001b[0m, \u001b[38;5;34m254\u001b[0m, \u001b[38;5;34m32\u001b[0m)   │           \u001b[38;5;34m896\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d (\u001b[38;5;33mMaxPooling2D\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m127\u001b[0m, \u001b[38;5;34m127\u001b[0m, \u001b[38;5;34m32\u001b[0m)   │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_1 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m125\u001b[0m, \u001b[38;5;34m125\u001b[0m, \u001b[38;5;34m64\u001b[0m)   │        \u001b[38;5;34m18,496\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_1 (\u001b[38;5;33mMaxPooling2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m62\u001b[0m, \u001b[38;5;34m62\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_2 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m60\u001b[0m, \u001b[38;5;34m60\u001b[0m, \u001b[38;5;34m128\u001b[0m)    │        \u001b[38;5;34m73,856\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ global_average_pooling2d        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "│ (\u001b[38;5;33mGlobalAveragePooling2D\u001b[0m)        │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │        \u001b[38;5;34m16,512\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lambda (\u001b[38;5;33mLambda\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">109,760</span> (428.75 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m109,760\u001b[0m (428.75 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">109,760</span> (428.75 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m109,760\u001b[0m (428.75 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def build_embedding_network(input_shape=(256, 256, 3)):\n",
    "    model = models.Sequential([\n",
    "        layers.Conv2D(32, (3, 3), activation='relu', input_shape=input_shape),\n",
    "        layers.MaxPooling2D((2, 2)),\n",
    "        layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "        layers.MaxPooling2D((2, 2)),\n",
    "        layers.Conv2D(128, (3, 3), activation='relu'),\n",
    "        layers.GlobalAveragePooling2D(),\n",
    "        layers.Dense(128, activation='relu'),  # Embedding dimension\n",
    "        layers.Lambda(lambda x: tf.math.l2_normalize(x, axis=1))  # Normalize embeddings\n",
    "    ])\n",
    "    return model\n",
    "\n",
    "embedding_model = build_embedding_network()\n",
    "embedding_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_1\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional_1\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)        </span>┃<span style=\"font-weight: bold\"> Output Shape      </span>┃<span style=\"font-weight: bold\">    Param # </span>┃<span style=\"font-weight: bold\"> Connected to      </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ anchor (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>,  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)                │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ positive            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>,  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │ <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)                │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ negative            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>,  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │ <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)                │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ sequential          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │    <span style=\"color: #00af00; text-decoration-color: #00af00\">109,760</span> │ anchor[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],     │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Sequential</span>)        │                   │            │ positive[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],   │\n",
       "│                     │                   │            │ negative[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ anchor (\u001b[38;5;33mInputLayer\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m256\u001b[0m,  │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "│                     │ \u001b[38;5;34m3\u001b[0m)                │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ positive            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m256\u001b[0m,  │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │ \u001b[38;5;34m3\u001b[0m)                │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ negative            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m256\u001b[0m,  │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │ \u001b[38;5;34m3\u001b[0m)                │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ sequential          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │    \u001b[38;5;34m109,760\u001b[0m │ anchor[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],     │\n",
       "│ (\u001b[38;5;33mSequential\u001b[0m)        │                   │            │ positive[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],   │\n",
       "│                     │                   │            │ negative[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">109,760</span> (428.75 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m109,760\u001b[0m (428.75 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">109,760</span> (428.75 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m109,760\u001b[0m (428.75 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def build_siamese_model(embedding_model, input_shape=(256, 256, 3)):\n",
    "    # Inputs for anchor, positive, and negative images\n",
    "    anchor_input = layers.Input(name=\"anchor\", shape=input_shape)\n",
    "    positive_input = layers.Input(name=\"positive\", shape=input_shape)\n",
    "    negative_input = layers.Input(name=\"negative\", shape=input_shape)\n",
    "\n",
    "    # Pass each input through the embedding network\n",
    "    anchor_embedding = embedding_model(anchor_input)\n",
    "    positive_embedding = embedding_model(positive_input)\n",
    "    negative_embedding = embedding_model(negative_input)\n",
    "\n",
    "    # Combine embeddings into a Siamese model\n",
    "    siamese_model = models.Model(\n",
    "        inputs=[anchor_input, positive_input, negative_input],\n",
    "        outputs=[anchor_embedding, positive_embedding, negative_embedding]\n",
    "    )\n",
    "\n",
    "    return siamese_model\n",
    "\n",
    "siamese_model = build_siamese_model(embedding_model)\n",
    "siamese_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For now lets use ready use resnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_resnet_embedding_network(input_shape=(256, 256, 3), embedding_dim=128):\n",
    "    # Load pre-trained ResNet50 without the top layer\n",
    "    base_model = ResNet50(weights=\"imagenet\", include_top=False, input_shape=input_shape)\n",
    "    \n",
    "    # Freeze the base model's weights (optional, for fine-tuning later)\n",
    "    base_model.trainable = False\n",
    "    \n",
    "    # Add custom layers for embedding extraction\n",
    "    model = models.Sequential([\n",
    "        base_model,\n",
    "        layers.GlobalAveragePooling2D(),\n",
    "        layers.Dense(embedding_dim, activation='relu'),  # Embedding dimension\n",
    "        layers.Lambda(lambda x: tf.math.l2_normalize(x, axis=1))  # L2 normalize embeddings\n",
    "    ])\n",
    "    \n",
    "    return model\n",
    "\n",
    "# Create the embedding network\n",
    "embedding_model = build_resnet_embedding_network()\n",
    "embedding_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_siamese_model_with_resnet(embedding_model, input_shape=(256, 256, 3)):\n",
    "    # Inputs for anchor, positive, and negative images\n",
    "    anchor_input = layers.Input(name=\"anchor\", shape=input_shape)\n",
    "    positive_input = layers.Input(name=\"positive\", shape=input_shape)\n",
    "    negative_input = layers.Input(name=\"negative\", shape=input_shape)\n",
    "\n",
    "    # Pass each input through the embedding network\n",
    "    anchor_embedding = embedding_model(anchor_input)\n",
    "    positive_embedding = embedding_model(positive_input)\n",
    "    negative_embedding = embedding_model(negative_input)\n",
    "\n",
    "    # Combine embeddings into a Siamese model\n",
    "    siamese_model = models.Model(\n",
    "        inputs=[anchor_input, positive_input, negative_input],\n",
    "        outputs=[anchor_embedding, positive_embedding, negative_embedding]\n",
    "    )\n",
    "\n",
    "    return siamese_model\n",
    "\n",
    "siamese_model = build_siamese_model_with_resnet(embedding_model)\n",
    "siamese_model.summary()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "CV2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
