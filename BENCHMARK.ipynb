{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "from PIL import Image as PILImage\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "import glob\n",
    "import os\n",
    "\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.applications import ResNet50\n",
    "from tensorflow.keras.utils import Sequence\n",
    "\n",
    "from tensorflow.keras.layers import GlobalAveragePooling2D\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "from keras.layers import Layer\n",
    "\n",
    "from annoy import AnnoyIndex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGE_SIZE = (256, 256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def imshow(a, size=1.0):\n",
    "    # Clip and convert the image to uint8\n",
    "    a = a.clip(0, 255).astype(\"uint8\")\n",
    "    \n",
    "    # Resize the image if a size factor is provided\n",
    "    if size != 1.0:\n",
    "        new_dim = (int(a.shape[1] * size), int(a.shape[0] * size))\n",
    "        a = cv2.resize(a, new_dim, interpolation=cv2.INTER_AREA)\n",
    "    \n",
    "\n",
    "    # Display the image\n",
    "    display(PILImage.fromarray(a))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class L2Normalization(Layer):\n",
    "    def call(self, inputs):\n",
    "        return tf.math.l2_normalize(inputs, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_image(file_path):\n",
    "    img = cv2.imread(file_path)\n",
    "    img = cv2.resize(img, IMAGE_SIZE)\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_folder = \"Data/00*\"\n",
    "image_files = glob.glob(os.path.join(data_folder, \"*.jpg\"), recursive=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#PURE RESNET\n",
    "\n",
    "base_model = ResNet50(weights='imagenet', include_top=False, input_shape=(256, 256, 3))\n",
    "\n",
    "# Add a Global Average Pooling layer to get 1D embeddings\n",
    "x = base_model.output\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "\n",
    "# Create the model for embedding extraction\n",
    "model_pure_resnet = Model(inputs=base_model.input, outputs=x)\n",
    "\n",
    "embedding_dimension = 2048\n",
    "index_pure_resnet = AnnoyIndex(embedding_dimension, 'euclidean')\n",
    "index_pure_resnet.load('Annoys/embeddings_resnet_index_big.ann')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #TRIPLET LEARNING RESNET FROZEN WEIGHTS\n",
    "\n",
    "# model_resnet_frozen =load_model(\"Models/embedding_resnet_model_big.keras\",\n",
    "#     custom_objects={\"L2Normalization\": L2Normalization})\n",
    "\n",
    "# embedding_dimension = 512\n",
    "# index_resnet_frozen = AnnoyIndex(embedding_dimension, 'euclidean')\n",
    "# index_resnet_frozen.load('Annoys/embeddings_index_big.ann')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #TRIPLET LEARNING RESNET TRAINED WEIGHTS\n",
    "\n",
    "# model_resnet_trained =load_model(\"Models/Embedding_resnet_model_exp_big.keras\", \n",
    "#     custom_objects={\"L2Normalization\": L2Normalization})\n",
    "\n",
    "# embedding_dimension = 512\n",
    "# index_resnet_trained = AnnoyIndex(embedding_dimension, 'euclidean')\n",
    "# index_resnet_trained.load('Annoys/embeddings_index_resnet_exp_big.ann')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#CUSTOM EMBEDDING MODEL\n",
    "\n",
    "model_custom = load_model(\"Models/embedding_custom_big.keras\",\n",
    "    custom_objects={\"L2Normalization\": L2Normalization})\n",
    "\n",
    "embedding_dimension = 512\n",
    "index_custom = AnnoyIndex(embedding_dimension, 'euclidean')\n",
    "index_custom.load('Annoys/embeddings_index_custom_big.ann')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#CUSTOM EMBEDDING MODEL\n",
    "\n",
    "model_base = load_model(\"Models/embedding_extractor_custom_big.keras\",\n",
    "    custom_objects={\"L2Normalization\": L2Normalization})\n",
    "\n",
    "embedding_dimension = 512\n",
    "index_base = AnnoyIndex(embedding_dimension, 'angular')\n",
    "index_base.load('Annoys/custom_extractor_big.ann')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#CUSTOM EMBEDDING MODEL\n",
    "\n",
    "model_transfer_1 = load_model(\"Models/transfer_custom_big.keras\",\n",
    "    custom_objects={\"L2Normalization\": L2Normalization})\n",
    "\n",
    "embedding_dimension = 512\n",
    "index_transfer_1 = AnnoyIndex(embedding_dimension, 'angular')\n",
    "index_transfer_1.load('Annoys/custom_transfer_big.ann')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#CUSTOM EMBEDDING MODEL\n",
    "\n",
    "model_transfer_2 = load_model(\"Models/transfer_custom_big_2.keras\",\n",
    "    custom_objects={\"L2Normalization\": L2Normalization})\n",
    "\n",
    "embedding_dimension = 512\n",
    "index_transfer_2 = AnnoyIndex(embedding_dimension, 'angular')\n",
    "index_transfer_2.load('Annoys/custom_transfer_big_2.ann')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #CUSTOM EMBEDDING MODEL\n",
    "\n",
    "# model_transfer_3 = load_model(\"Models/transfer_custom_3.keras\",\n",
    "#     custom_objects={\"L2Normalization\": L2Normalization})\n",
    "\n",
    "# embedding_dimension = 512\n",
    "# index_transfer_3 = AnnoyIndex(embedding_dimension, 'angular')\n",
    "# index_transfer_3.load('Annoys/custom_transfer_3.ann')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BENCHMARK THEM ALL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "query_folder = \"Queries_Small/*\"\n",
    "query_files = glob.glob(query_folder)\n",
    "\n",
    "# models = [model_pure_resnet, model_resnet_frozen, model_resnet_trained, model_custom]\n",
    "# indexes = [index_pure_resnet, index_resnet_frozen, index_resnet_trained, index_custom]\n",
    "# names = [\"Pure ResNet\", \"ResNet Frozen\", \"ResNet Trained\", \"Custom\"]\n",
    "\n",
    "models = [model_base, model_transfer_1, model_transfer_2, model_transfer_3]\n",
    "indexes = [index_base, index_transfer_1, index_transfer_2, index_transfer_3]\n",
    "names = [\"Base\", \"Transfer 1\", \"Transfer 2\", \"Transfer 3\"]\n",
    "\n",
    "for query in query_files:\n",
    "    img = read_image(query)\n",
    "    \n",
    "    matches = []\n",
    "    \n",
    "    for i in range(len(names)):\n",
    "        model = models[i]\n",
    "        index = indexes[i]\n",
    "        name = names[i]\n",
    "        \n",
    "        embedding = model.predict(np.expand_dims(img, axis=0))[0]\n",
    "        embedding = np.array(embedding)\n",
    "        \n",
    "        similar_image_indices, distances = index.get_nns_by_vector(embedding, n=1, include_distances=True)\n",
    "        \n",
    "        matches.append(image_files[similar_image_indices[0]])\n",
    "       \n",
    "        \n",
    "    fig, axes = plt.subplots(1, 5, figsize=(15, 5))\n",
    "    \n",
    "    axes[0].imshow(img)\n",
    "    axes[0].set_title(\"Query\")\n",
    "    axes[0].axis(\"off\")\n",
    "    \n",
    "    axes[1].imshow(read_image(matches[0]))\n",
    "    axes[1].set_title(f\"Model: {names[0]}\")\n",
    "    axes[1].axis(\"off\")\n",
    "    \n",
    "    axes[2].imshow(read_image(matches[1]))\n",
    "    axes[2].set_title(f\"Model: {names[1]}\")\n",
    "    axes[2].axis(\"off\")\n",
    "    \n",
    "    axes[3].imshow(read_image(matches[2]))\n",
    "    axes[3].set_title(f\"Model: {names[2]}\")\n",
    "    axes[3].axis(\"off\")\n",
    "    \n",
    "    axes[4].imshow(read_image(matches[3]))\n",
    "    axes[4].set_title(f\"Model: {names[3]}\")\n",
    "    axes[4].axis(\"off\")\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "CV2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
